<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>WebRTC AV Player</title>
  <style>
    body { font-family: Arial, sans-serif; padding: 1rem; }
    video { width: 640px; height: 360px; background: #000; border-radius: 12px; }
    button { padding: 0.5rem 1rem; margin-top: 1rem; font-size: 1rem; margin-right: .5rem; }
    #log { margin-top: .5rem; color: #666; font-size: .9rem;}
  </style>
</head>
<body>
  <h2>ğŸï¸ WebRTC éŸ³è§†é¢‘æ’­æ”¾ï¼ˆå«éº¦å…‹é£ä¸Šè¡Œï¼‰</h2>
  <video id="video" playsinline autoplay controls></video>
  <br/>
  <button id="start">å¼€å§‹</button>
  <button id="stop" disabled>ç»“æŸ</button>
  <button id="mute" disabled>é™éŸ³æœ¬åœ°éº¦å…‹é£</button>
  <div id="log"></div>

<script>
(() => {
  const $ = (id) => document.getElementById(id);
  const log = (...args) => { $('log').textContent = args.join(' '); };

  let pc = null;
  let audioTransceiver = null;
  let localMicTrack = null;
  let remoteStream = null;

  const videoElem = $('video');

  function setUIState(running) {
    $('start').disabled = running;
    $('stop').disabled = !running;
    $('mute').disabled = !running || !localMicTrack;
    $('mute').textContent = (localMicTrack && localMicTrack.enabled) ? 'é™éŸ³æœ¬åœ°éº¦å…‹é£' : 'å–æ¶ˆé™éŸ³';
  }

  function attachRemoteTrackEvents() {
    remoteStream = new MediaStream();
    pc.addEventListener("track", (event) => {
      remoteStream.addTrack(event.track);
      if (videoElem.srcObject !== remoteStream) {
        videoElem.srcObject = remoteStream;
      }
    });
  }

  function addTransceivers() {
    // ä¸‹è¡Œï¼šåªæ¥æ”¶è§†é¢‘
    pc.addTransceiver('video', { direction: 'recvonly' });
    // éŸ³é¢‘ï¼šé»˜è®¤åŒå‘ï¼ˆæ—¢æ¥æ”¶åç«¯éŸ³é¢‘ï¼Œåˆå‘é€æœ¬åœ°éº¦å…‹é£ï¼‰
    audioTransceiver = pc.addTransceiver('audio', { direction: 'sendrecv' });
  }

  async function waitForIceComplete() {
    if (pc.iceGatheringState === "complete") return;
    await new Promise(resolve => {
      pc.addEventListener("icegatheringstatechange", () => {
        if (pc.iceGatheringState === "complete") resolve();
      });
    });
  }

  async function startSession() {
    if (pc) return; // å·²åœ¨è¿è¡Œ
    log('åˆå§‹åŒ–ä¼šè¯â€¦');

    pc = new RTCPeerConnection({
      iceServers: [{ urls: "stun:stun.l.google.com:19302" }]
    });

    // ç»“æŸ/å¤±è´¥æ—¶çš„æ¸…ç†
    pc.addEventListener('connectionstatechange', () => {
      if (['failed','closed','disconnected'].includes(pc.connectionState)) {
        stopSession(/*fromStateChange*/true);
      }
    });

    attachRemoteTrackEvents();
    addTransceivers();

    // ç”³è¯·æœ¬åœ°éº¦å…‹é£å¹¶ç»‘å®šåˆ°å‘é€ç«¯ï¼›ç”¨æˆ·æ‹’ç»æ—¶é™çº§ä¸ºä»…æ¥æ”¶
    localMicTrack = null;
    try {
      log('è¯·æ±‚éº¦å…‹é£æƒé™â€¦');
      const micStream = await navigator.mediaDevices.getUserMedia({
        audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true }
      });
      localMicTrack = micStream.getAudioTracks()[0];
      await audioTransceiver.sender.replaceTrack(localMicTrack);
      log('å·²è·å–éº¦å…‹é£ï¼Œå»ºç«‹è¿æ¥â€¦');
    } catch (err) {
      console.warn('getUserMedia å¤±è´¥ï¼š', err);
      log('éº¦å…‹é£ä¸å¯ç”¨ï¼šä»…æ’­æ”¾è¿œç«¯éŸ³è§†é¢‘ã€‚');
      try {
        await audioTransceiver.sender.replaceTrack(null);
        audioTransceiver.direction = 'recvonly';
      } catch (_) {}
    }

    // SDP äº¤æ¢
    await pc.setLocalDescription(await pc.createOffer());
    await waitForIceComplete();

    const resp = await fetch("/offer", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(pc.localDescription)
    });

    if (!resp.ok) {
      log('ä¿¡ä»¤å¤±è´¥ï¼š', resp.status, await resp.text());
      // å‡ºé”™ç«‹å³æ”¶å°¾
      await stopSession();
      return;
    }

    const answer = await resp.json();
    await pc.setRemoteDescription(answer);

    setUIState(true);
    log('è¿æ¥å·²å»ºç«‹ âœ… æ­£åœ¨æ”¶/å‘éŸ³è§†é¢‘â€¦');
  }

  async function stopSession(fromStateChange = false) {
    // åœæ­¢æœ¬åœ°éº¦å…‹é£
    try { localMicTrack && localMicTrack.stop(); } catch(_) {}

    // åœæ­¢å‘é€ç«¯è½¨é“
    if (pc) {
      pc.getSenders().forEach(s => {
        try { s.track && s.track.stop(); } catch(_) {}
        try { s.replaceTrack(null); } catch(_) {}
      });
      // åœæ­¢æ¥æ”¶ç«¯è½¨é“
      pc.getReceivers().forEach(r => { try { r.track && r.track.stop(); } catch(_) {} });
      try { pc.close(); } catch(_) {}
    }

    // è§£é™¤è¿œç«¯æ’­æ”¾
    if (remoteStream) {
      remoteStream.getTracks().forEach(t => { try { t.stop(); } catch(_) {} });
    }
    videoElem.srcObject = null;

    // æ¸…ç©ºå¼•ç”¨ï¼Œä¾¿äºä¸‹æ¬¡â€œå¼€å§‹â€é‡æ–°åˆ›å»º
    pc = null;
    audioTransceiver = null;
    localMicTrack = null;
    remoteStream = null;

    setUIState(false);
    if (!fromStateChange) log('ä¼šè¯å·²ç»“æŸ â¹ï¸');
  }

  // æœ¬åœ°é™éŸ³/æ¢å¤ï¼ˆä¸é‡å»ºä¼šè¯ï¼‰
  $('mute').addEventListener('click', () => {
    if (!localMicTrack) return;
    localMicTrack.enabled = !localMicTrack.enabled;
    $('mute').textContent = localMicTrack.enabled ? 'é™éŸ³æœ¬åœ°éº¦å…‹é£' : 'å–æ¶ˆé™éŸ³';
  });

  $('start').addEventListener('click', startSession);
  $('stop').addEventListener('click', () => stopSession());

  // é¡µé¢å…³é—­å‰çš„å…œåº•æ¸…ç†
  window.addEventListener('beforeunload', () => stopSession());
})();
</script>
</body>
</html>
